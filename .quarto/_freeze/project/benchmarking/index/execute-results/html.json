{
  "hash": "74a352d1f55570da85b099c488f85948",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Can Ravens Forecast?\"\ndate: \"2018-07-29\"\ncategories: [R, time series, forecast]\ndescription: \"Time series forecasting using cloud services spend data\"\n# bibliography: references.bib\n---\n\n\n![](feature.gif){fig-alt=\"A silhouette of the Houses of Parliament with rain pouring down on a man holding an umbrella and a raven swooping across the sky\"}\n\nHumans have the magical ability to plan for future events, for future gain. It's [not quite a uniquely human trait](https://www.newscientist.com/article/2140668-ravens-can-plan-for-future-as-well-as-4-year-old-children-can/). Because apparently ravens can match a four-year-old.\n\nAn abundance of data, and some very nice R packages, make our ability to plan all the more powerful.\n\nIn the Spring of 2018 I looked at sales from an historical perspective in [Six Months Later.](/project/six). Here I'll use the data to model a time-series forecast for the year ahead. The techniques apply to any time series with characteristics of trend, seasonality or longer-term cycles.\n\nWhy forecast sales? Business plans require a budget, e.g. for resources, marketing and office space. A good projection of revenue provides the foundation for the budget. And, for an established business, with historical data, time-series forecasting is one way to deliver a robust projection.\n\nWithout exogenous data, the forecast assumes one continues to do what one's doing. So, it provides a good starting-point. Then one might, for example, add assumptions about new products or services. And, if there is forward-looking data available, for example, market size projections (with past projections to train the model), then one could feed this into the forecast modelling too.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(conflicted)\nlibrary(tidyverse)\nconflict_prefer_all(\"dplyr\")\nlibrary(wesanderson)\nlibrary(fpp3)\nlibrary(scales)\nlibrary(clock)\nlibrary(usedthese)\n\nconflict_scout()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntheme_set(theme_bw())\n\n(cols <- wes_palette(name = \"IsleofDogs2\"))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/theme-1.png){width=100%}\n:::\n:::\n\n\nFirst I'll check the encoding of the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nurl <-\n  \"https://www.gov.uk/government/uploads/system/uploads/attachment_data/file/\"\n\ngcloud_csv <- str_c(url, \"703943/G-Cloud_spend_data_to_end_March_2018.csv\")\n\ndos_csv <- str_c(url, \"703952/DOS_spend_data_to_end_March_2018.csv\")\n\nnames <- c(gcloud_csv, dos_csv)\n\n# Use walk to suppress the printing of list element numbers\n\nwalk(names, \\(x) {\n  p <- guess_encoding(x)\n  print(p)\n})\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  encoding   confidence\n  <chr>           <dbl>\n1 ISO-8859-1       0.4 \n2 ISO-8859-2       0.22\n# A tibble: 2 × 2\n  encoding   confidence\n  <chr>           <dbl>\n1 ISO-8859-1       0.36\n2 ISO-8859-2       0.24\n```\n\n\n:::\n:::\n\n\nNext I'll set up a vector of column names to apply consistently to both files, and import the data with the suggested encoding.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncolnam <- \n  c(\"sector\",\n    \"lot\",\n    \"date\",\n    \"spend\",\n    \"status\",\n    \"supplier\",\n    \"customer\",\n    \"framework\")\n\nread_dm <- \\(x){\n  read_csv(\n    x,\n    col_names = colnam,\n    skip = 1,\n    locale = locale(encoding = \"ISO-8859-1\"),\n    show_col_types = FALSE)\n}\n\nraw <- map(names, read_dm) |> \n  set_names(c(\"gcloud\", \"dos\")) |> \n  bind_rows() |> \n  mutate(framework = if_else(is.na(framework), \"DOS\", framework))\n```\n:::\n\n\nI'd like to create some new features: Month-end dates, something to distinguish between the two frameworks (*G-Cloud* or *DOS*). The spend has a messy format and needs a bit of cleaning too.\n\nThe lot structure for *G-Cloud* has evolved over time, but fortunately, there is a simple mapping, i.e. *PaaS* and *IaaS* became *Cloud Hosting*, *SaaS* became *Cloud Software*, and *Specialist Cloud Services* became *Cloud Support*, so I'll standardise on the latter.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nboth <- raw |>\n  mutate(\n    month_end = date_parse(str_c(date, \"01\", sep = \"-\"), \n                           format = \"%b-%y-%d\") |> \n      add_months(1) |> add_days(-1),\n    date = yearmonth(month_end),\n    framework = str_extract(framework, \".{3,7}\"),\n    spend = str_remove(spend, coll(\"£\")),\n    spend = str_replace(spend, \"^\\\\(\", \"-\"),\n    spend = parse_number(spend) / 1000000,\n    lot = recode(\n      lot,\n      \"Software as a Service (SaaS)\" = \"Cloud Software\",\n      \"Infrastructure as a Service (IaaS)\" = \"Cloud Hosting\",\n      \"Platform as a Service (PaaS)\" = \"Cloud Hosting\",\n      \"Specialist Cloud Services\" = \"Cloud Support\"\n      )\n)\n```\n:::\n\n\nThe tidied data now needs to be converted to a [tsibble](https://github.com/tidyverts/tsibble)[@tsibble], the temporal equivalent of a [tibble](https://tibble.tidyverse.org)[@tibble].\n\nR has evolved since I first wrote this post. At that time, it was necessary to either split the data into the two frameworks (G-Cloud and DOS) and forecast them separately. Or, as I did with the three G-Cloud lots, use the purrr package to iterate through a forecast.\n\nThe tsibble package combined with the newer fable[@fable] and feasts[@feasts] packages, make this easier. One of the defining feature of the tsibble is the `key`. I want a model for each framework, so I'm setting this as the tsibble `key` (and the temporal variable as the tsibble `index`).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nboth_ts <- both |>\n  summarise(spend = sum(spend), .by = c(date, framework)) |> \n  as_tsibble(key = framework, index = date)\n\nboth_ts |> \n  ggplot(aes(date, spend, colour = framework)) +\n  geom_line(key_glyph = \"timeseries\") +\n  scale_y_continuous(labels = label_dollar(prefix = \"£\", suffix = \"m\")) +\n  scale_colour_manual(values = cols[c(3, 4)]) +\n  labs(x = NULL, y = NULL, title = \"Monthly Digital Marketplace Sales\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot sales-1.png){width=100%}\n:::\n:::\n\n\nBy decomposing the historical data we can tease out the underlying trend and seasonality:\n\n-   **Trend**: The sales for both frameworks have grown over time as more Suppliers have added their services to the Government frameworks, and more Public Sector organizations have found the benefits of purchasing Cloud services through this faster, simpler, more transparent and more competitive contracting vehicle.\n\n-   **Seasonality**: Suppliers often manage their sales and financials based on a quarterly cycle, with a particular emphasis on a strong close to the financial year. And Government Buyers may want to make optimal use of their budgets at the close of their financial year (March 31st). Consequently, we see quarterly seasonality with an extra spike at financial year-end.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nboth_ts |>\n  model(stl = STL(spend ~ trend(window = 7) + season(window = \"periodic\"))) |>\n  components() |>\n  autoplot() +\n  scale_colour_manual(values = cols[c(3, 4)]) +\n  labs(x = NULL, title = \"Time Series Decomposition\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/decomposition-1.png){width=100%}\n:::\n:::\n\n\nI'll use `auto.arima`: [AutoRegressive Integrated Moving Average](https://en.wikipedia.org/wiki/Autoregressive_integrated_moving_average) modelling which aims to describe the autocorrelations in the data.\n\nBy setting `stepwise` and `approximation` to `FALSE`, `auto.arima` will explore a wider range of potential models.\n\nI'll forecast with the default 80% and 95% prediction intervals. This means the darker-shaded 80% range should include the future sales value with an 80% probability. Likewise with a 95% probability when adding the wider and lighter-shaded area.\n\nUse of `autoplot` would simplify the code, but personally I like to expose all the data, for example unpacking the prediction intervals, and have finer control over the visualisation.",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}